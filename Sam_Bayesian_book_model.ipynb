{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select relevant columns\n",
    "df = df[['User-ID', 'ISBN', 'Book-Rating']]\n",
    "\n",
    "# Encode User-ID and ISBN as categorical (Used as array indices in PyMC)\n",
    "df['User-Index'] = df['User-ID'].astype(\"category\").cat.codes\n",
    "df['Book-Index'] = df['ISBN'].astype(\"category\").cat.codes\n",
    "\n",
    "# Get number of unique users and books\n",
    "num_users = df['User-Index'].nunique()\n",
    "num_books = df['Book-Index'].nunique()\n",
    "\n",
    "# Convert to numpy arrays for modeling\n",
    "user_ids = df['User-Index'].values\n",
    "book_ids = df['Book-Index'].values\n",
    "ratings = df['Book-Rating'].values  # Use raw ratings since we're using Poisson\n",
    "\n",
    "print(\"Number of unique users:\", num_users)\n",
    "print(\"Number of unique books:\", num_books)\n",
    "\n",
    "# Set a higher latent dimension to capture more complex user-book interactions\n",
    "latent_dim = 10  \n",
    "\n",
    "# Calculate rating counts per user and book to adjust priors based on sparsity\n",
    "user_rating_counts = df.groupby('User-Index')['Book-Rating'].count()\n",
    "book_rating_counts = df.groupby('Book-Index')['Book-Rating'].count()\n",
    "\n",
    "# Avoid division by zero by replacing zeros with a small number\n",
    "user_rating_counts[user_rating_counts == 0] = 1\n",
    "book_rating_counts[book_rating_counts == 0] = 1\n",
    "\n",
    "# Bayesian Probabilistic Matrix Factorization Model with Gamma-Poisson\n",
    "with pm.Model() as model:\n",
    "    # Prior for global mean rating (Gamma ensures positive values)\n",
    "    mu = pm.Gamma(\"mu\", alpha=2, beta=0.5)\n",
    "    \n",
    "    # User and book bias priors adjusted for sparsity\n",
    "    user_bias = pm.Normal(\"user_bias\", mu=0, sigma=1 / np.sqrt(user_rating_counts[df['User-Index']]), shape=num_users)\n",
    "    book_bias = pm.Normal(\"book_bias\", mu=0, sigma=1 / np.sqrt(book_rating_counts[df['Book-Index']]), shape=num_books)\n",
    "\n",
    "    # Hierarchical priors for user and book latent factors\n",
    "    sigma_u = pm.HalfCauchy(\"sigma_u\", beta=1)\n",
    "    sigma_b = pm.HalfCauchy(\"sigma_b\", beta=1)\n",
    "    \n",
    "    user_factors = pm.Normal(\"user_factors\", mu=0, sigma=sigma_u, shape=(num_users, latent_dim))\n",
    "    book_factors = pm.Normal(\"book_factors\", mu=0, sigma=sigma_b, shape=(num_books, latent_dim))\n",
    "\n",
    "    # Expected rating using Poisson lambda\n",
    "    lambda_rating = pm.math.exp(\n",
    "        mu +\n",
    "        user_bias[df['User-Index']] +\n",
    "        book_bias[df['Book-Index']] +\n",
    "        (user_factors[df['User-Index']] * book_factors[df['Book-Index']]).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    # Poisson likelihood for discrete ratings\n",
    "    ratings_obs = pm.Poisson(\"ratings_obs\", mu=lambda_rating, observed=ratings)\n",
    "    \n",
    "    # Use No-U-Turn Sampler (NUTS) for efficient MCMC sampling\n",
    "    trace = pm.sample(\n",
    "        draws=1000,  \n",
    "        tune=1000,  \n",
    "        step=pm.NUTS(),  \n",
    "        cores=2,  \n",
    "        random_seed=42,  \n",
    "        return_inferencedata=True\n",
    "    )\n",
    "\n",
    "# Posterior Predictive Sampling\n",
    "with model:\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace, var_names=[\"ratings_obs\"], random_seed=42)\n",
    "    sampled_ratings = posterior_predictive[\"ratings_obs\"]\n",
    "\n",
    "# Print an example subset of predicted ratings\n",
    "print(\"\\nExample of Predicted Ratings (posterior predictive mean):\")\n",
    "print(sampled_ratings.mean(axis=0)[:5])  \n",
    "\n",
    "# ---- Bayes General Multi-Step Lookahead Recommendation ---- #\n",
    "\n",
    "def bayes_general_recommendation(user_index, book_indices, trace, top_k=5, exploration_factor=0.5, regret_threshold=0.8, max_regret=2.0):\n",
    "    \"\"\"\n",
    "    Multi-step lookahead Bayesian regret minimization for recommending 5 books.\n",
    "    \n",
    "    user_index: ID of the user\n",
    "    book_indices: List of book IDs available for recommendation.\n",
    "    trace: Posterior samples from our Bayesian model.\n",
    "    top_k: Number of books to recommend (default=5).\n",
    "    exploration_factor: Weight for future expected gain vs. immediate reward.\n",
    "    regret_threshold: Minimum regret required to trigger exploration.\n",
    "    max_regret: Upper limit on regret to prevent excessive exploration.\n",
    "    \"\"\"\n",
    "    # Sample from the full posterior\n",
    "    mu_samples = trace[\"mu\"]\n",
    "    user_bias_samples = trace[\"user_bias\"][:, user_index]\n",
    "    book_bias_samples = trace[\"book_bias\"][:, book_indices]\n",
    "    user_factors_samples = trace[\"user_factors\"][:, user_index, :]\n",
    "    book_factors_samples = trace[\"book_factors\"][:, book_indices, :]\n",
    "\n",
    "    num_samples = len(mu_samples)  # Number of MCMC samples\n",
    "    \n",
    "    # Compute expected rewards using posterior sampling\n",
    "    expected_rewards = np.mean(\n",
    "        np.exp(mu_samples[:, None] + user_bias_samples[:, None] + book_bias_samples +\n",
    "               np.sum(user_factors_samples[:, None, :] * book_factors_samples, axis=2)), axis=0\n",
    "    )\n",
    "\n",
    "    # Compute variance (uncertainty measure)\n",
    "    rating_uncertainty = np.var(\n",
    "        np.exp(mu_samples[:, None] + user_bias_samples[:, None] + book_bias_samples +\n",
    "               np.sum(user_factors_samples[:, None, :] * book_factors_samples, axis=2)), axis=0\n",
    "    )\n",
    "    \n",
    "    # Compute Bayesian regret\n",
    "    best_expected_reward = np.max(expected_rewards)\n",
    "    regrets = best_expected_reward - expected_rewards\n",
    "\n",
    "    # Cap regret to prevent extreme exploration\n",
    "    regrets = np.clip(regrets, 0, max_regret)\n",
    "\n",
    "    # Apply regret threshold\n",
    "    should_explore = regrets > regret_threshold\n",
    "\n",
    "    # Compute future learning potential\n",
    "    expected_future_gain = exploration_factor * rating_uncertainty\n",
    "\n",
    "    # Compute exploration-adjusted score\n",
    "    exploration_score = expected_rewards + expected_future_gain\n",
    "\n",
    "    # Rank books\n",
    "    ranked_books = np.argsort(-exploration_score)  # Sort in descending order\n",
    "\n",
    "    # Select top-k books for recommendation\n",
    "    selected_books = [book_indices[i] for i in ranked_books[:top_k]]\n",
    "\n",
    "    return selected_books\n",
    "\n",
    "# Example usage: Recommend 5 books for a user\n",
    "user_id_example = 42  # Replace with an actual user ID\n",
    "book_pool = np.arange(num_books)  # Assuming all books are available\n",
    "\n",
    "recommended_books = bayes_general_recommendation(user_id_example, book_pool, trace, top_k=5)\n",
    "print(\"\\nTop-5 Recommended Books for User\", user_id_example, \":\", recommended_books)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasterBayesianVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
