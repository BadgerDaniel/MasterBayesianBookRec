{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"C:\\mingw64\\bin\\g++.EXE\"\n",
      "['DebugMode__check_c', 'DebugMode__check_finite', 'DebugMode__check_preallocated_output', 'DebugMode__check_preallocated_output_ndim', 'DebugMode__check_py', 'DebugMode__check_strides', 'DebugMode__patience', 'DebugMode__warn_input_not_reused', 'NanGuardMode__action', 'NanGuardMode__big_is_error', 'NanGuardMode__inf_is_error', 'NanGuardMode__nan_is_error', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_config_var_dict', '_flags_dict', '_pytensor_cfg', '_pytensor_raw_cfg', 'add', 'allow_gc', 'base_compiledir', 'blas__check_openmp', 'blas__ldflags', 'cast_policy', 'change_flags', 'check_input', 'check_stack_trace', 'cmodule__age_thresh_use', 'cmodule__compilation_warning', 'cmodule__debug', 'cmodule__preload_cache', 'cmodule__remove_gxx_opt', 'cmodule__warn_no_version', 'compile__timeout', 'compile__wait', 'compiledir', 'compiledir_format', 'compute_test_value', 'compute_test_value_opt', 'config_print', 'conv__assert_shape', 'cxx', 'cycle_detection', 'device', 'exception_verbosity', 'fetch_val_for_key', 'floatX', 'gcc__cxxflags', 'get_config_hash', 'lib__amdlibm', 'linker', 'metaopt__verbose', 'mode', 'nocleanup', 'numba__cache', 'numba__fastmath', 'numba__vectorize_target', 'on_opt_error', 'on_shape_error', 'on_unused_input', 'openmp', 'openmp_elemwise_minsize', 'optdb__max_use_ratio', 'optdb__position_cutoff', 'optimizer', 'optimizer_excluding', 'optimizer_including', 'optimizer_requiring', 'optimizer_verbose', 'pickle_test_value', 'print_global_stats', 'print_test_value', 'profile', 'profile_memory', 'profile_optimizer', 'profiling__debugprint', 'profiling__destination', 'profiling__ignore_first_call', 'profiling__min_memory_size', 'profiling__min_peak_memory', 'profiling__n_apply', 'profiling__n_ops', 'profiling__output_line_width', 'profiling__time_thunks', 'scan__allow_gc', 'scan__allow_output_prealloc', 'tensor__cmp_sloppy', 'tensor__insert_inplace_optimizer_validate_nb', 'traceback__compile_limit', 'traceback__limit', 'unittests__rseed', 'unpickle_function', 'vm__lazy', 'warn__ignore_bug_before', 'warn__round', 'warn_float64', 'warn_unused_flags']\n",
      "-LC:\\OpenBLAS\\lib -lopenblas\n",
      "BLAS flags: -LC:\\OpenBLAS\\lib -lopenblas\n",
      "Computation Mode: Mode\n"
     ]
    }
   ],
   "source": [
    "#import pytensor\n",
    "#print(pytensor.config.cxx)\n",
    "\n",
    "#set up g++ and openBLAS\n",
    "\n",
    "#import pytensor\n",
    "#print(dir(pytensor.config))\n",
    "\n",
    "#import pytensor\n",
    "#pytensor.config.blas__ldflags = '-LC:\\\\OpenBLAS\\\\lib -lopenblas'\n",
    "#print(pytensor.config.blas__ldflags)\n",
    "\n",
    "#import pytensor\n",
    "#print(\"BLAS flags:\", pytensor.config.blas__ldflags)\n",
    "# print(\"Computation Mode:\", pytensor.config.mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE ADVI (only 1000 rows for testing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 838\n",
      "Number of unique books: 977\n",
      "Running Variational Inference (ADVI)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6349500f5f2e4c7c946e8332cc043e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished [100%]: Average Loss = 3,234.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manually Generating Predictions Using Posterior Samples...\n",
      "\n",
      "Example of Predicted Ratings (posterior predictive mean):\n",
      "[4.98980722 5.02430613 4.28409701 0.45939204 0.63903444]\n",
      "\n",
      "Top-5 Recommended Books for User 42 : [872, 134, 3, 171, 755]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel(\"book_ratings.xlsx\")\n",
    "\n",
    "# Select relevant columns\n",
    "df = df[['User-ID', 'ISBN', 'Book-Rating']]\n",
    "\n",
    "# **Downsample to 1000 random rows for testing**\n",
    "df = df.sample(n=1000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Encode User-ID and ISBN as categorical for indexing\n",
    "df['User-Index'] = df['User-ID'].astype(\"category\").cat.codes\n",
    "df['Book-Index'] = df['ISBN'].astype(\"category\").cat.codes\n",
    "\n",
    "# **Remap indices to contiguous range** (Fixes the IndexError)\n",
    "df['User-Index'] = df['User-Index'].astype(\"category\").cat.codes\n",
    "df['Book-Index'] = df['Book-Index'].astype(\"category\").cat.codes\n",
    "\n",
    "# Get updated number of unique users and books\n",
    "num_users = df['User-Index'].nunique()\n",
    "num_books = df['Book-Index'].nunique()\n",
    "\n",
    "# Convert to numpy arrays for modeling\n",
    "user_ids = df['User-Index'].values\n",
    "book_ids = df['Book-Index'].values\n",
    "ratings = df['Book-Rating'].values  # Using raw ratings for Poisson\n",
    "\n",
    "print(\"Number of unique users:\", num_users)\n",
    "print(\"Number of unique books:\", num_books)\n",
    "\n",
    "# Set latent dimension \n",
    "latent_dim = 5\n",
    "\n",
    "# Compute rating counts per user and book\n",
    "user_rating_counts = df.groupby('User-Index')['Book-Rating'].count()\n",
    "book_rating_counts = df.groupby('Book-Index')['Book-Rating'].count()\n",
    "\n",
    "# Avoid division by zero\n",
    "user_rating_counts[user_rating_counts == 0] = 1\n",
    "book_rating_counts[book_rating_counts == 0] = 1\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "user_ids_np = df['User-Index'].to_numpy()\n",
    "book_ids_np = df['Book-Index'].to_numpy()\n",
    "\n",
    "# Bayesian Probabilistic Matrix Factorization Model with Gamma-Poisson\n",
    "with pm.Model() as model:\n",
    "    # Prior for global mean rating\n",
    "    mu = pm.Gamma(\"mu\", alpha=2, beta=0.5)\n",
    "    \n",
    "    # User and book bias priors\n",
    "    user_bias = pm.Normal(\"user_bias\", mu=0, sigma=1 / np.sqrt(user_rating_counts + 1), shape=num_users)\n",
    "    book_bias = pm.Normal(\"book_bias\", mu=0, sigma=1 / np.sqrt(book_rating_counts + 1), shape=num_books)\n",
    "\n",
    "    # Hierarchical priors for latent factors\n",
    "    sigma_u = pm.HalfCauchy(\"sigma_u\", beta=1)\n",
    "    sigma_b = pm.HalfCauchy(\"sigma_b\", beta=1)\n",
    "    \n",
    "    user_factors = pm.Normal(\"user_factors\", mu=0, sigma=sigma_u, shape=(num_users, latent_dim))\n",
    "    book_factors = pm.Normal(\"book_factors\", mu=0, sigma=sigma_b, shape=(num_books, latent_dim))\n",
    "\n",
    "    # Expected rating using Poisson lambda\n",
    "    lambda_rating = pm.math.exp(\n",
    "        mu +\n",
    "        user_bias[user_ids_np] +\n",
    "        book_bias[book_ids_np] +\n",
    "        (user_factors[user_ids_np] * book_factors[book_ids_np]).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    # Poisson likelihood\n",
    "    ratings_obs = pm.Poisson(\"ratings_obs\", mu=lambda_rating, observed=ratings)\n",
    "    \n",
    "    # Use ADVI for fast variational inference instead of NUTS\n",
    "    print(\"Running Variational Inference (ADVI)...\")\n",
    "    approx = pm.fit(n=50000, method=\"advi\")\n",
    "    trace = approx.sample(draws=2000)\n",
    "\n",
    "# **Extract posterior values manually since PyMC won't sample `ratings_obs`**\n",
    "with model:\n",
    "    print(\"\\nManually Generating Predictions Using Posterior Samples...\")\n",
    "    \n",
    "    # Extract posterior values\n",
    "    mu_post = trace.posterior[\"mu\"].mean().item()\n",
    "    user_bias_post = trace.posterior[\"user_bias\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    book_bias_post = trace.posterior[\"book_bias\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    user_factors_post = trace.posterior[\"user_factors\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    book_factors_post = trace.posterior[\"book_factors\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "\n",
    "    # Compute expected ratings\n",
    "    predicted_ratings = np.exp(\n",
    "        mu_post + \n",
    "        user_bias_post[user_ids_np] + \n",
    "        book_bias_post[book_ids_np] +\n",
    "        (user_factors_post[user_ids_np] * book_factors_post[book_ids_np]).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    print(\"\\nExample of Predicted Ratings (posterior predictive mean):\")\n",
    "    print(predicted_ratings[:5])\n",
    "\n",
    "# ---- Bayes General Multi-Step Lookahead Recommendation ---- #\n",
    "\n",
    "def bayes_general_recommendation(user_index, book_indices, trace, top_k=5, exploration_factor=0.5, regret_threshold=0.8, max_regret=2.0):\n",
    "    \"\"\"\n",
    "    Multi-step lookahead Bayesian regret minimization for recommending 5 books.\n",
    "    \"\"\"\n",
    "    mu_samples = trace.posterior[\"mu\"].values\n",
    "    user_bias_samples = trace.posterior[\"user_bias\"].values[:, :, user_index]\n",
    "    book_bias_samples = trace.posterior[\"book_bias\"].values[:, :, book_indices]\n",
    "    user_factors_samples = trace.posterior[\"user_factors\"].values[:, :, user_index, :]\n",
    "    book_factors_samples = trace.posterior[\"book_factors\"].values[:, :, book_indices, :]\n",
    "\n",
    "    num_samples = mu_samples.shape[1]  # Number of posterior samples\n",
    "    \n",
    "    # Compute expected rewards using posterior sampling\n",
    "    expected_rewards = np.mean(\n",
    "        np.exp(mu_samples[:, :, None] + user_bias_samples[:, :, None] + book_bias_samples +\n",
    "               np.sum(user_factors_samples[:, :, None, :] * book_factors_samples, axis=-1)), axis=1\n",
    "    )\n",
    "\n",
    "    # Compute variance (uncertainty measure)\n",
    "    rating_uncertainty = np.var(\n",
    "        np.exp(mu_samples[:, :, None] + user_bias_samples[:, :, None] + book_bias_samples +\n",
    "               np.sum(user_factors_samples[:, :, None, :] * book_factors_samples, axis=-1)), axis=1\n",
    "    )\n",
    "    \n",
    "    # Compute Bayesian regret\n",
    "    best_expected_reward = np.max(expected_rewards, axis=1)\n",
    "    regrets = best_expected_reward[:, None] - expected_rewards\n",
    "\n",
    "    # Cap regret to prevent extreme exploration\n",
    "    regrets = np.clip(regrets, 0, max_regret)\n",
    "\n",
    "    # Apply regret threshold\n",
    "    should_explore = regrets > regret_threshold\n",
    "\n",
    "    # Compute future learning potential\n",
    "    expected_future_gain = exploration_factor * rating_uncertainty\n",
    "\n",
    "    # Compute exploration-adjusted score\n",
    "    exploration_score = expected_rewards + expected_future_gain\n",
    "\n",
    "    # Rank books\n",
    "    ranked_books = np.argsort(-exploration_score, axis=1)  # Sort in descending order\n",
    "\n",
    "    # Select top-k books for recommendation\n",
    "    selected_books = [book_indices[i] for i in ranked_books[0, :top_k]]\n",
    "\n",
    "    return selected_books\n",
    "\n",
    "# Example usage: Recommend 5 books for a user\n",
    "user_id_example = 42  # Replace with an actual user ID\n",
    "book_pool = np.arange(num_books)  # Assuming all books are available\n",
    "\n",
    "recommended_books = bayes_general_recommendation(user_id_example, book_pool, trace, top_k=5)\n",
    "print(\"\\nTop-5 Recommended Books for User\", user_id_example, \":\", recommended_books)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasterBayesianVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
