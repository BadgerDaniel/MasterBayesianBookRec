{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"C:\\mingw64\\bin\\g++.EXE\"\n",
      "['DebugMode__check_c', 'DebugMode__check_finite', 'DebugMode__check_preallocated_output', 'DebugMode__check_preallocated_output_ndim', 'DebugMode__check_py', 'DebugMode__check_strides', 'DebugMode__patience', 'DebugMode__warn_input_not_reused', 'NanGuardMode__action', 'NanGuardMode__big_is_error', 'NanGuardMode__inf_is_error', 'NanGuardMode__nan_is_error', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_config_var_dict', '_flags_dict', '_pytensor_cfg', '_pytensor_raw_cfg', 'add', 'allow_gc', 'base_compiledir', 'blas__check_openmp', 'blas__ldflags', 'cast_policy', 'change_flags', 'check_input', 'check_stack_trace', 'cmodule__age_thresh_use', 'cmodule__compilation_warning', 'cmodule__debug', 'cmodule__preload_cache', 'cmodule__remove_gxx_opt', 'cmodule__warn_no_version', 'compile__timeout', 'compile__wait', 'compiledir', 'compiledir_format', 'compute_test_value', 'compute_test_value_opt', 'config_print', 'conv__assert_shape', 'cxx', 'cycle_detection', 'device', 'exception_verbosity', 'fetch_val_for_key', 'floatX', 'gcc__cxxflags', 'get_config_hash', 'lib__amdlibm', 'linker', 'metaopt__verbose', 'mode', 'nocleanup', 'numba__cache', 'numba__fastmath', 'numba__vectorize_target', 'on_opt_error', 'on_shape_error', 'on_unused_input', 'openmp', 'openmp_elemwise_minsize', 'optdb__max_use_ratio', 'optdb__position_cutoff', 'optimizer', 'optimizer_excluding', 'optimizer_including', 'optimizer_requiring', 'optimizer_verbose', 'pickle_test_value', 'print_global_stats', 'print_test_value', 'profile', 'profile_memory', 'profile_optimizer', 'profiling__debugprint', 'profiling__destination', 'profiling__ignore_first_call', 'profiling__min_memory_size', 'profiling__min_peak_memory', 'profiling__n_apply', 'profiling__n_ops', 'profiling__output_line_width', 'profiling__time_thunks', 'scan__allow_gc', 'scan__allow_output_prealloc', 'tensor__cmp_sloppy', 'tensor__insert_inplace_optimizer_validate_nb', 'traceback__compile_limit', 'traceback__limit', 'unittests__rseed', 'unpickle_function', 'vm__lazy', 'warn__ignore_bug_before', 'warn__round', 'warn_float64', 'warn_unused_flags']\n",
      "-LC:\\OpenBLAS\\lib -lopenblas\n",
      "BLAS flags: -LC:\\OpenBLAS\\lib -lopenblas\n",
      "Computation Mode: Mode\n"
     ]
    }
   ],
   "source": [
    "#import pytensor\n",
    "#print(pytensor.config.cxx)\n",
    "\n",
    "#set up g++ and openBLAS\n",
    "\n",
    "#import pytensor\n",
    "#print(dir(pytensor.config))\n",
    "\n",
    "#import pytensor\n",
    "#pytensor.config.blas__ldflags = '-LC:\\\\OpenBLAS\\\\lib -lopenblas'\n",
    "#print(pytensor.config.blas__ldflags)\n",
    "\n",
    "#import pytensor\n",
    "#print(\"BLAS flags:\", pytensor.config.blas__ldflags)\n",
    "# print(\"Computation Mode:\", pytensor.config.mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE ADVI (only 1000 rows for testing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, precision_score, recall_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel(\"book_ratings.xlsx\")\n",
    "\n",
    "# Select relevant columns\n",
    "df = df[['User-ID', 'ISBN', 'Book-Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Downsample to 1000 random rows for testing**\n",
    "df = df.sample(n=1000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode User-ID and ISBN as categorical for indexing\n",
    "df['User-Index'] = df['User-ID'].astype(\"category\").cat.codes\n",
    "df['Book-Index'] = df['ISBN'].astype(\"category\").cat.codes\n",
    "\n",
    "# **Remap indices to contiguous range** (Fixes the IndexError)\n",
    "df['User-Index'] = df['User-Index'].astype(\"category\").cat.codes\n",
    "df['Book-Index'] = df['Book-Index'].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute rating counts per user and book\n",
    "user_rating_counts = df.groupby('User-Index')['Book-Rating'].count()\n",
    "book_rating_counts = df.groupby('Book-Index')['Book-Rating'].count()\n",
    "\n",
    "# Avoid division by zero\n",
    "user_rating_counts[user_rating_counts == 0] = 1\n",
    "book_rating_counts[book_rating_counts == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays for modeling\n",
    "train_user_ids = train_df['User-Index'].values\n",
    "test_user_ids = test_df['User-Index'].values\n",
    "train_book_ids = train_df['Book-Index'].values\n",
    "test_book_ids = test_df['Book-Index'].values\n",
    "train_ratings = train_df['Book-Rating'].values # Using raw ratings for Poisson\n",
    "test_ratings = test_df['Book-Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 838\n",
      "Number of unique books: 977\n"
     ]
    }
   ],
   "source": [
    "# Get updated number of unique users and books\n",
    "num_users = df['User-Index'].nunique()\n",
    "num_books = df['Book-Index'].nunique()\n",
    "\n",
    "print(\"Number of unique users:\", num_users)\n",
    "print(\"Number of unique books:\", num_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Variational Inference (ADVI)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301173166a5c4e11ad7b112904f02b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished [100%]: Average Loss = 2,768.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manually Generating Predictions Using Posterior Samples...\n",
      "\n",
      "Example of Predicted Ratings (posterior predictive mean):\n",
      "[0.77044243 0.66189129 1.07396004 0.99871736 1.03573795]\n",
      "Mean Absolute Error (MAE): 3.2976\n",
      "Root Mean Squared Error (RMSE): 4.4131\n"
     ]
    }
   ],
   "source": [
    "# Set latent dimension \n",
    "latent_dim = 5\n",
    "\n",
    "# Bayesian Probabilistic Matrix Factorization Model with Gamma-Poisson\n",
    "with pm.Model() as model:\n",
    "    # Prior for global mean rating\n",
    "    mu = pm.Gamma(\"mu\", alpha=2, beta=0.5)\n",
    "    \n",
    "    # User and book bias priors\n",
    "    user_bias = pm.Normal(\"user_bias\", mu=0, sigma=1 / np.sqrt(user_rating_counts + 1), shape=num_users)\n",
    "    book_bias = pm.Normal(\"book_bias\", mu=0, sigma=1 / np.sqrt(book_rating_counts + 1), shape=num_books)\n",
    "\n",
    "    # Hierarchical priors for latent factors\n",
    "    sigma_u = pm.HalfCauchy(\"sigma_u\", beta=1)\n",
    "    sigma_b = pm.HalfCauchy(\"sigma_b\", beta=1)\n",
    "    \n",
    "    user_factors = pm.Normal(\"user_factors\", mu=0, sigma=sigma_u, shape=(num_users, latent_dim))\n",
    "    book_factors = pm.Normal(\"book_factors\", mu=0, sigma=sigma_b, shape=(num_books, latent_dim))\n",
    "\n",
    "    # Expected rating using Poisson lambda\n",
    "    lambda_rating = pm.math.exp(\n",
    "        mu +\n",
    "        user_bias[train_user_ids] +\n",
    "        book_bias[train_book_ids] +\n",
    "        (user_factors[train_user_ids] * book_factors[train_book_ids]).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    # Poisson likelihood\n",
    "    ratings_obs = pm.Poisson(\"ratings_obs\", mu=lambda_rating, observed=train_ratings)\n",
    "    \n",
    "    # Use ADVI for fast variational inference instead of NUTS\n",
    "    print(\"Running Variational Inference (ADVI)...\")\n",
    "    approx = pm.fit(n=50000, method=\"advi\")\n",
    "    trace = approx.sample(draws=2000)\n",
    "\n",
    "# **Extract posterior values manually since PyMC won't sample `ratings_obs`**\n",
    "with model:\n",
    "    print(\"\\nManually Generating Predictions Using Posterior Samples...\")\n",
    "    \n",
    "    # Extract posterior values\n",
    "    mu_post = trace.posterior[\"mu\"].mean().item()\n",
    "    user_bias_post = trace.posterior[\"user_bias\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    book_bias_post = trace.posterior[\"book_bias\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    user_factors_post = trace.posterior[\"user_factors\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    book_factors_post = trace.posterior[\"book_factors\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "\n",
    "    # Compute expected ratings\n",
    "    predicted_ratings = np.exp(\n",
    "        mu_post + \n",
    "        user_bias_post[test_user_ids] + \n",
    "        book_bias_post[test_book_ids] +\n",
    "        (user_factors_post[test_user_ids] * book_factors_post[test_book_ids]).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    print(\"\\nExample of Predicted Ratings (posterior predictive mean):\")\n",
    "    print(predicted_ratings[:5])\n",
    "    \n",
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(test_ratings, predicted_ratings)\n",
    "rmse = np.sqrt(mean_squared_error(test_ratings, predicted_ratings))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Variational Inference (ADVI)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b43375581394eda8447dea6a854fbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished [100%]: Average Loss = 2,790.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Variational Inference (ADVI)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m     approx \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mfit(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madvi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m     trace \u001b[38;5;241m=\u001b[39m \u001b[43mapprox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# **Extract posterior values manually since PyMC won't sample `ratings_obs`**\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/pymc/variational/opvi.py:1559\u001b[0m, in \u001b[0;36mApproximation.sample\u001b[0;34m(self, draws, random_seed, return_inferencedata, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(names, _samples))\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner\n\u001b[0;32m-> 1559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msample\u001b[39m(\n\u001b[1;32m   1560\u001b[0m     \u001b[38;5;28mself\u001b[39m, draws\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m*\u001b[39m, random_seed: RandomState \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, return_inferencedata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1561\u001b[0m ):\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Draw samples from variational posterior.\u001b[39;00m\n\u001b[1;32m   1563\u001b[0m \n\u001b[1;32m   1564\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;124;03m        Samples drawn from variational posterior.\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m     \u001b[38;5;66;03m# TODO: add tests for include_transformed case\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_trace_dispatch_regular.py:493\u001b[0m, in \u001b[0;36mThreadTracer.__call__\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m NO_FTRACE\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# if DEBUG: print('trace_dispatch', filename, frame.f_lineno, event, frame.f_code.co_name, file_type)\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Just create PyDBFrame directly (removed support for Python versions < 2.5, which required keeping a weak\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# reference to the frame).\u001b[39;00m\n\u001b[1;32m    484\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mPyDBFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpy_db\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_path_canonical_path_and_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe_skips_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# 1 means skipped because of filters.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;66;03m# 2 means skipped because no breakpoints were hit.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m     cache_skips[frame_cache_key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:768\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:172\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2185\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2182\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2184\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2185\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2187\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2190\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2254\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2251\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2252\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2254\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2255\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set latent dimension \n",
    "latent_dim = 5\n",
    "\n",
    "# Bayesian Probabilistic Matrix Factorization Model with Gamma-Poisson\n",
    "with pm.Model() as model:\n",
    "    # Prior for global mean rating\n",
    "    mu = pm.Gamma(\"mu\", alpha=2, beta=0.5)\n",
    "    \n",
    "    # User and book bias priors\n",
    "    user_bias = pm.Normal(\"user_bias\", mu=0, sigma=1 / np.sqrt(user_rating_counts + 1), shape=num_users)\n",
    "    book_bias = pm.Normal(\"book_bias\", mu=0, sigma=1 / np.sqrt(book_rating_counts + 1), shape=num_books)\n",
    "\n",
    "    # Hierarchical priors for latent factors\n",
    "    sigma_u = pm.HalfCauchy(\"sigma_u\", beta=1)\n",
    "    sigma_b = pm.HalfCauchy(\"sigma_b\", beta=1)\n",
    "    \n",
    "    user_factors = pm.Normal(\"user_factors\", mu=0, sigma=sigma_u, shape=(num_users, latent_dim))\n",
    "    book_factors = pm.Normal(\"book_factors\", mu=0, sigma=sigma_b, shape=(num_books, latent_dim))\n",
    "\n",
    "    # Expected rating using Poisson lambda\n",
    "    lambda_rating = pm.math.exp(\n",
    "        mu +\n",
    "        user_bias[train_user_ids] +\n",
    "        book_bias[train_book_ids] +\n",
    "        (user_factors[train_user_ids] * book_factors[train_book_ids]).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    # Poisson likelihood\n",
    "    ratings_obs = pm.Poisson(\"ratings_obs\", mu=lambda_rating, observed=train_ratings)\n",
    "    \n",
    "    # Use ADVI for fast variational inference instead of NUTS\n",
    "    print(\"Running Variational Inference (ADVI)...\")\n",
    "    approx = pm.fit(n=50000, method=\"advi\")\n",
    "    trace = approx.sample(draws=2000)\n",
    "\n",
    "# **Extract posterior values manually since PyMC won't sample `ratings_obs`**\n",
    "with model:\n",
    "    print(\"\\nManually Generating Predictions Using Posterior Samples...\")\n",
    "    \n",
    "    # Extract posterior values\n",
    "    mu_post = trace.posterior[\"mu\"].mean().item()\n",
    "    user_bias_post = trace.posterior[\"user_bias\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    book_bias_post = trace.posterior[\"book_bias\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    user_factors_post = trace.posterior[\"user_factors\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    book_factors_post = trace.posterior[\"book_factors\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "\n",
    "    # Compute expected ratings\n",
    "    predicted_ratings = np.exp(\n",
    "        mu_post + \n",
    "        user_bias_post[test_user_ids] + \n",
    "        book_bias_post[test_book_ids] +\n",
    "        (user_factors_post[test_user_ids] * book_factors_post[test_book_ids]).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    print(\"\\nExample of Predicted Ratings (posterior predictive mean):\")\n",
    "    print(predicted_ratings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 3.2976\n",
      "Root Mean Squared Error (RMSE): 4.4131\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(test_ratings, predicted_ratings)\n",
    "rmse = np.sqrt(mean_squared_error(test_ratings, predicted_ratings))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.3869\n",
      "RMSE: 1.8813\n",
      "Precision: 0.7037\n",
      "Recall: 0.7037\n",
      "MAE: 3.2975\n",
      "RMSE: 4.4130\n",
      "Precision: 0.6950\n",
      "Recall: 0.6950\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of Precision, Recall, MAE, and RMSE\n",
    "\n",
    "def evaluate_predictions(true_ratings, predicted_ratings, threshold=7):\n",
    "    mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
    "    rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
    "    \n",
    "    # Convert to binary relevance (1 if rating >= threshold, else 0)\n",
    "    true_binary = (true_ratings >= threshold).astype(int)\n",
    "    predicted_binary = (predicted_ratings >= threshold).astype(int)\n",
    "    \n",
    "    precision = precision_score(true_binary, predicted_binary, average='micro')\n",
    "    recall = recall_score(true_binary, predicted_binary, average='micro')\n",
    "    \n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Running evaluation\n",
    "predicted_train_ratings = np.exp(\n",
    "    trace.posterior[\"mu\"].mean().item() +\n",
    "    trace.posterior[\"user_bias\"].mean(dim=(\"chain\", \"draw\")).values[train_user_ids] +\n",
    "    trace.posterior[\"book_bias\"].mean(dim=(\"chain\", \"draw\")).values[train_book_ids]\n",
    ")\n",
    "predicted_test_ratings = np.exp(\n",
    "    trace.posterior[\"mu\"].mean().item() +\n",
    "    trace.posterior[\"user_bias\"].mean(dim=(\"chain\", \"draw\")).values[test_user_ids] +\n",
    "    trace.posterior[\"book_bias\"].mean(dim=(\"chain\", \"draw\")).values[test_book_ids]\n",
    ")\n",
    "\n",
    "evaluate_predictions(train_ratings, predicted_train_ratings)\n",
    "evaluate_predictions(test_ratings, predicted_test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-5 Recommended Books for User 42 : [586, 438, 140, 27, 555]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Bayes General Multi-Step Lookahead Recommendation ---- #\n",
    "\n",
    "def bayes_general_recommendation(user_index, book_indices, trace, top_k=5, exploration_factor=0.5, regret_threshold=0.8, max_regret=2.0):\n",
    "    \"\"\"\n",
    "    Multi-step lookahead Bayesian regret minimization for recommending 5 books.\n",
    "    \"\"\"\n",
    "    mu_samples = trace.posterior[\"mu\"].values\n",
    "    user_bias_samples = trace.posterior[\"user_bias\"].values[:, :, user_index]\n",
    "    book_bias_samples = trace.posterior[\"book_bias\"].values[:, :, book_indices]\n",
    "    user_factors_samples = trace.posterior[\"user_factors\"].values[:, :, user_index, :]\n",
    "    book_factors_samples = trace.posterior[\"book_factors\"].values[:, :, book_indices, :]\n",
    "\n",
    "    num_samples = mu_samples.shape[1]  # Number of posterior samples\n",
    "    \n",
    "    # Compute expected rewards using posterior sampling\n",
    "    expected_rewards = np.mean(\n",
    "        np.exp(mu_samples[:, :, None] + user_bias_samples[:, :, None] + book_bias_samples +\n",
    "               np.sum(user_factors_samples[:, :, None, :] * book_factors_samples, axis=-1)), axis=1\n",
    "    )\n",
    "\n",
    "    # Compute variance (uncertainty measure)\n",
    "    rating_uncertainty = np.var(\n",
    "        np.exp(mu_samples[:, :, None] + user_bias_samples[:, :, None] + book_bias_samples +\n",
    "               np.sum(user_factors_samples[:, :, None, :] * book_factors_samples, axis=-1)), axis=1\n",
    "    )\n",
    "    \n",
    "    # Compute Bayesian regret\n",
    "    best_expected_reward = np.max(expected_rewards, axis=1)\n",
    "    regrets = best_expected_reward[:, None] - expected_rewards\n",
    "\n",
    "    # Cap regret to prevent extreme exploration\n",
    "    regrets = np.clip(regrets, 0, max_regret)\n",
    "\n",
    "    # Apply regret threshold\n",
    "    should_explore = regrets > regret_threshold\n",
    "\n",
    "    # Compute future learning potential\n",
    "    expected_future_gain = exploration_factor * rating_uncertainty\n",
    "\n",
    "    # Compute exploration-adjusted score\n",
    "    exploration_score = expected_rewards + expected_future_gain\n",
    "\n",
    "    # Rank books\n",
    "    ranked_books = np.argsort(-exploration_score, axis=1)  # Sort in descending order\n",
    "\n",
    "    # Select top-k books for recommendation\n",
    "    selected_books = [book_indices[i] for i in ranked_books[0, :top_k]]\n",
    "\n",
    "    return selected_books\n",
    "\n",
    "# Example usage: Recommend 5 books for a user\n",
    "user_id_example = 42  # Replace with an actual user ID\n",
    "book_pool = np.arange(num_books)  # Assuming all books are available\n",
    "\n",
    "recommended_books = bayes_general_recommendation(user_id_example, book_pool, trace, top_k=5)\n",
    "print(\"\\nTop-5 Recommended Books for User\", user_id_example, \":\", recommended_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision@5: 0.0010\n",
      "Average Recall@5: 0.0050\n",
      "Mean Absolute Error (MAE): 2.9559\n",
      "Root Mean Squared Error (RMSE): 3.0136\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of Precision, Recall, MAE, and RMSE in the top 5 recommendations\n",
    "\n",
    "def evaluate_recommendations(user_ids, book_pool, trace, top_k=5):\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_mae = 0\n",
    "    total_rmse = 0\n",
    "    user_count = len(user_ids)\n",
    "    \n",
    "    for user in user_ids:\n",
    "        actual_books = set(test_df[test_df['User-Index'] == user]['Book-Index'].values)\n",
    "        actual_ratings = test_df[test_df['User-Index'] == user]['Book-Rating'].values\n",
    "        recommended_books = set(bayes_general_recommendation(user, book_pool, trace, top_k))\n",
    "        \n",
    "        if len(actual_books) > 0:\n",
    "            precision = len(recommended_books & actual_books) / top_k\n",
    "            recall = len(recommended_books & actual_books) / len(actual_books)\n",
    "            predicted_ratings = np.array([trace.posterior[\"mu\"].mean().item() + trace.posterior[\"user_bias\"].mean(dim=(\"chain\", \"draw\")).values[user] + trace.posterior[\"book_bias\"].mean(dim=(\"chain\", \"draw\")).values[book] for book in actual_books])\n",
    "            \n",
    "            mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "            rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "        else:\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            mae = 0\n",
    "            rmse = 0\n",
    "        \n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_mae += mae\n",
    "        total_rmse += rmse\n",
    "    \n",
    "    avg_precision = total_precision / user_count\n",
    "    avg_recall = total_recall / user_count\n",
    "    avg_mae = total_mae / user_count\n",
    "    avg_rmse = total_rmse / user_count\n",
    "    \n",
    "    print(f\"Average Precision@{top_k}: {avg_precision:.4f}\")\n",
    "    print(f\"Average Recall@{top_k}: {avg_recall:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {avg_mae:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {avg_rmse:.4f}\")\n",
    "\n",
    "# Running evaluation\n",
    "book_pool = np.arange(num_books)\n",
    "evaluate_recommendations(test_user_ids, book_pool, trace, top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
