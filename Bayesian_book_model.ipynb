{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pytensor\n",
    "#print(pytensor.config.cxx)\n",
    "\n",
    "#set up g++ and openBLAS\n",
    "\n",
    "#import pytensor\n",
    "#print(dir(pytensor.config))\n",
    "\n",
    "#import pytensor\n",
    "#pytensor.config.blas__ldflags = '-LC:\\\\OpenBLAS\\\\lib -lopenblas'\n",
    "#print(pytensor.config.blas__ldflags)\n",
    "\n",
    "#import pytensor\n",
    "#print(\"BLAS flags:\", pytensor.config.blas__ldflags)\n",
    "# print(\"Computation Mode:\", pytensor.config.mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE ADVI (only 1000 rows for testing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, precision_score, recall_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbook_ratings_cleaned.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Select relevant columns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISBN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBook-Rating\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel(\"book_ratings_cleaned.xlsx\")\n",
    "\n",
    "# Select relevant columns\n",
    "df = df[['User-ID', 'ISBN', 'Book-Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop zero values as they are not the actual rating\n",
    "df = df[df['Book-Rating'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383840"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the data\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>276744</td>\n",
       "      <td>038550120X</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>276747</td>\n",
       "      <td>0060517794</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User-ID        ISBN  Book-Rating\n",
       "1    276726  0155061224            5\n",
       "3    276729  052165615X            3\n",
       "4    276729  0521795028            6\n",
       "6    276744  038550120X            7\n",
       "13   276747  0060517794            9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Downsample to 1000 random rows for testing**\n",
    "# df = df.sample(n=1000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode User-ID and ISBN as categorical for indexing\n",
    "df['User-Index'] = df['User-ID'].astype(\"category\").cat.codes\n",
    "df['Book-Index'] = df['ISBN'].astype(\"category\").cat.codes\n",
    "\n",
    "# **Remap indices to contiguous range** (Fixes the IndexError)\n",
    "df['User-Index'] = df['User-Index'].astype(\"category\").cat.codes\n",
    "df['Book-Index'] = df['Book-Index'].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute rating counts per user and book\n",
    "user_rating_counts = df.groupby('User-Index')['Book-Rating'].count()\n",
    "book_rating_counts = df.groupby('Book-Index')['Book-Rating'].count()\n",
    "\n",
    "# Avoid division by zero\n",
    "user_rating_counts[user_rating_counts == 0] = 1\n",
    "book_rating_counts[book_rating_counts == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays for modeling\n",
    "train_user_ids = train_df['User-Index'].values\n",
    "test_user_ids = test_df['User-Index'].values\n",
    "train_book_ids = train_df['Book-Index'].values\n",
    "test_book_ids = test_df['Book-Index'].values\n",
    "train_ratings = train_df['Book-Rating'].values # Using raw ratings for Poisson\n",
    "test_ratings = test_df['Book-Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 838\n",
      "Number of unique books: 977\n"
     ]
    }
   ],
   "source": [
    "# Get updated number of unique users and books\n",
    "num_users = df['User-Index'].nunique()\n",
    "num_books = df['Book-Index'].nunique()\n",
    "\n",
    "print(\"Number of unique users:\", num_users)\n",
    "print(\"Number of unique books:\", num_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Variational Inference (ADVI)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301173166a5c4e11ad7b112904f02b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished [100%]: Average Loss = 2,768.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manually Generating Predictions Using Posterior Samples...\n",
      "\n",
      "Example of Predicted Ratings (posterior predictive mean):\n",
      "[0.77044243 0.66189129 1.07396004 0.99871736 1.03573795]\n",
      "Mean Absolute Error (MAE): 3.2976\n",
      "Root Mean Squared Error (RMSE): 4.4131\n"
     ]
    }
   ],
   "source": [
    "# Set latent dimension \n",
    "latent_dim = 5\n",
    "\n",
    "# Bayesian Probabilistic Matrix Factorization Model with Gamma-Poisson\n",
    "with pm.Model() as model:\n",
    "    # Prior for global mean rating\n",
    "    mu = pm.Gamma(\"mu\", alpha=2, beta=0.5)\n",
    "    \n",
    "    # ----- User and book bias priors (Adjust sigma for best performance) -----\n",
    "    user_bias = pm.Normal(\"user_bias\", mu=0, sigma=0.5 / np.sqrt(user_rating_counts + 1), shape=num_users)\n",
    "    book_bias = pm.Normal(\"book_bias\", mu=0, sigma=0.5 / np.sqrt(book_rating_counts + 1), shape=num_books)\n",
    "\n",
    "    # Hierarchical priors for latent factors (beta=1 worked best)\n",
    "    sigma_u = pm.HalfCauchy(\"sigma_u\", beta=1)\n",
    "    sigma_b = pm.HalfCauchy(\"sigma_b\", beta=1)\n",
    "    \n",
    "    user_factors = pm.Normal(\"user_factors\", mu=0, sigma=sigma_u, shape=(num_users, latent_dim))\n",
    "    book_factors = pm.Normal(\"book_factors\", mu=0, sigma=sigma_b, shape=(num_books, latent_dim))\n",
    "\n",
    "    # Expected rating using Poisson lambda\n",
    "    lambda_rating = pm.math.exp(\n",
    "        mu +\n",
    "        user_bias[train_user_ids] +\n",
    "        book_bias[train_book_ids] +\n",
    "        (user_factors[train_user_ids] * book_factors[train_book_ids]).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    # Poisson likelihood\n",
    "    ratings_obs = pm.Poisson(\"ratings_obs\", mu=lambda_rating, observed=train_ratings)\n",
    "    \n",
    "    # Use ADVI for fast variational inference instead of NUTS\n",
    "    print(\"Running Variational Inference (ADVI)...\")\n",
    "    approx = pm.fit(n=50000, method=\"advi\")\n",
    "    trace = approx.sample(draws=2000)\n",
    "\n",
    "# **Extract posterior values manually since PyMC won't sample `ratings_obs`**\n",
    "with model:\n",
    "    print(\"\\nManually Generating Predictions Using Posterior Samples...\")\n",
    "    \n",
    "    # Extract posterior values\n",
    "    mu_post = trace.posterior[\"mu\"].mean().item()\n",
    "    user_bias_post = trace.posterior[\"user_bias\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    book_bias_post = trace.posterior[\"book_bias\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    user_factors_post = trace.posterior[\"user_factors\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    book_factors_post = trace.posterior[\"book_factors\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "\n",
    "    # Compute expected ratings\n",
    "    predicted_ratings = np.exp(\n",
    "        mu_post + \n",
    "        user_bias_post[test_user_ids] + \n",
    "        book_bias_post[test_book_ids] +\n",
    "        (user_factors_post[test_user_ids] * book_factors_post[test_book_ids]).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    print(\"\\nExample of Predicted Ratings (posterior predictive mean):\")\n",
    "    print(predicted_ratings[:5])\n",
    "    \n",
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(test_ratings, predicted_ratings)\n",
    "rmse = np.sqrt(mean_squared_error(test_ratings, predicted_ratings))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Variational Inference (ADVI)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b43375581394eda8447dea6a854fbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished [100%]: Average Loss = 2,790.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Variational Inference (ADVI)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m     approx \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mfit(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madvi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m     trace \u001b[38;5;241m=\u001b[39m \u001b[43mapprox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# **Extract posterior values manually since PyMC won't sample `ratings_obs`**\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/pymc/variational/opvi.py:1559\u001b[0m, in \u001b[0;36mApproximation.sample\u001b[0;34m(self, draws, random_seed, return_inferencedata, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(names, _samples))\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner\n\u001b[0;32m-> 1559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msample\u001b[39m(\n\u001b[1;32m   1560\u001b[0m     \u001b[38;5;28mself\u001b[39m, draws\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m*\u001b[39m, random_seed: RandomState \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, return_inferencedata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1561\u001b[0m ):\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Draw samples from variational posterior.\u001b[39;00m\n\u001b[1;32m   1563\u001b[0m \n\u001b[1;32m   1564\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;124;03m        Samples drawn from variational posterior.\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m     \u001b[38;5;66;03m# TODO: add tests for include_transformed case\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_trace_dispatch_regular.py:493\u001b[0m, in \u001b[0;36mThreadTracer.__call__\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m NO_FTRACE\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# if DEBUG: print('trace_dispatch', filename, frame.f_lineno, event, frame.f_code.co_name, file_type)\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Just create PyDBFrame directly (removed support for Python versions < 2.5, which required keeping a weak\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# reference to the frame).\u001b[39;00m\n\u001b[1;32m    484\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mPyDBFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpy_db\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_path_canonical_path_and_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe_skips_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# 1 means skipped because of filters.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;66;03m# 2 means skipped because no breakpoints were hit.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m     cache_skips[frame_cache_key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:768\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:172\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2185\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2182\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2184\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2185\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2187\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2190\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2254\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2251\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2252\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2254\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2255\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bayes/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set latent dimension \n",
    "latent_dim = 5\n",
    "\n",
    "# Bayesian Probabilistic Matrix Factorization Model with Gamma-Poisson\n",
    "with pm.Model() as model:\n",
    "    # Prior for global mean rating\n",
    "    mu = pm.Gamma(\"mu\", alpha=2, beta=0.5)\n",
    "    \n",
    "    # User and book bias priors\n",
    "    user_bias = pm.Normal(\"user_bias\", mu=0, sigma=1 / np.sqrt(user_rating_counts + 1), shape=num_users)\n",
    "    book_bias = pm.Normal(\"book_bias\", mu=0, sigma=1 / np.sqrt(book_rating_counts + 1), shape=num_books)\n",
    "\n",
    "    # Hierarchical priors for latent factors\n",
    "    sigma_u = pm.HalfCauchy(\"sigma_u\", beta=1)\n",
    "    sigma_b = pm.HalfCauchy(\"sigma_b\", beta=1)\n",
    "    \n",
    "    user_factors = pm.Normal(\"user_factors\", mu=0, sigma=sigma_u, shape=(num_users, latent_dim))\n",
    "    book_factors = pm.Normal(\"book_factors\", mu=0, sigma=sigma_b, shape=(num_books, latent_dim))\n",
    "\n",
    "    # Expected rating using Poisson lambda\n",
    "    lambda_rating = pm.math.exp(\n",
    "        mu +\n",
    "        user_bias[train_user_ids] +\n",
    "        book_bias[train_book_ids] +\n",
    "        (user_factors[train_user_ids] * book_factors[train_book_ids]).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    # Poisson likelihood\n",
    "    ratings_obs = pm.Poisson(\"ratings_obs\", mu=lambda_rating, observed=train_ratings)\n",
    "    \n",
    "    # Use ADVI for fast variational inference instead of NUTS\n",
    "    print(\"Running Variational Inference (ADVI)...\")\n",
    "    approx = pm.fit(n=50000, method=\"advi\")\n",
    "    trace = approx.sample(draws=2000)\n",
    "\n",
    "# **Extract posterior values manually since PyMC won't sample `ratings_obs`**\n",
    "with model:\n",
    "    print(\"\\nManually Generating Predictions Using Posterior Samples...\")\n",
    "    \n",
    "    # Extract posterior values\n",
    "    mu_post = trace.posterior[\"mu\"].mean().item()\n",
    "    user_bias_post = trace.posterior[\"user_bias\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    book_bias_post = trace.posterior[\"book_bias\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    user_factors_post = trace.posterior[\"user_factors\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "    book_factors_post = trace.posterior[\"book_factors\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "\n",
    "    # Compute expected ratings\n",
    "    predicted_ratings = np.exp(\n",
    "        mu_post + \n",
    "        user_bias_post[test_user_ids] + \n",
    "        book_bias_post[test_book_ids] +\n",
    "        (user_factors_post[test_user_ids] * book_factors_post[test_book_ids]).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    print(\"\\nExample of Predicted Ratings (posterior predictive mean):\")\n",
    "    print(predicted_ratings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 3.2976\n",
      "Root Mean Squared Error (RMSE): 4.4131\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metrics\n",
    "mae = mean_absolute_error(test_ratings, predicted_ratings)\n",
    "rmse = np.sqrt(mean_squared_error(test_ratings, predicted_ratings))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.3869\n",
      "RMSE: 1.8813\n",
      "Precision: 0.7037\n",
      "Recall: 0.7037\n",
      "MAE: 3.2975\n",
      "RMSE: 4.4130\n",
      "Precision: 0.6950\n",
      "Recall: 0.6950\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of Precision, Recall, MAE, and RMSE\n",
    "\n",
    "def evaluate_predictions(true_ratings, predicted_ratings, threshold=7):\n",
    "    mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
    "    rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
    "    \n",
    "    # Convert to binary relevance (1 if rating >= threshold, else 0)\n",
    "    true_binary = (true_ratings >= threshold).astype(int)\n",
    "    predicted_binary = (predicted_ratings >= threshold).astype(int)\n",
    "    \n",
    "    precision = precision_score(true_binary, predicted_binary, average='micro')\n",
    "    recall = recall_score(true_binary, predicted_binary, average='micro')\n",
    "    \n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Running evaluation\n",
    "predicted_train_ratings = np.exp(\n",
    "    trace.posterior[\"mu\"].mean().item() +\n",
    "    trace.posterior[\"user_bias\"].mean(dim=(\"chain\", \"draw\")).values[train_user_ids] +\n",
    "    trace.posterior[\"book_bias\"].mean(dim=(\"chain\", \"draw\")).values[train_book_ids]\n",
    ")\n",
    "predicted_test_ratings = np.exp(\n",
    "    trace.posterior[\"mu\"].mean().item() +\n",
    "    trace.posterior[\"user_bias\"].mean(dim=(\"chain\", \"draw\")).values[test_user_ids] +\n",
    "    trace.posterior[\"book_bias\"].mean(dim=(\"chain\", \"draw\")).values[test_book_ids]\n",
    ")\n",
    "\n",
    "evaluate_predictions(train_ratings, predicted_train_ratings)\n",
    "evaluate_predictions(test_ratings, predicted_test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-5 Recommended Books for User 42 : [586, 438, 140, 27, 555]\n"
     ]
    }
   ],
   "source": [
    "# ---- Bayes General Multi-Step Lookahead Recommendation ---- #\n",
    "\n",
    "def bayes_general_recommendation(user_index, book_indices, trace, top_k=5, exploration_factor=0.5, regret_threshold=0.8, max_regret=2.0):\n",
    "    \"\"\"\n",
    "    Multi-step lookahead Bayesian regret minimization for recommending 5 books.\n",
    "    \"\"\"\n",
    "    mu_samples = trace.posterior[\"mu\"].values\n",
    "    user_bias_samples = trace.posterior[\"user_bias\"].values[:, :, user_index]\n",
    "    book_bias_samples = trace.posterior[\"book_bias\"].values[:, :, book_indices]\n",
    "    user_factors_samples = trace.posterior[\"user_factors\"].values[:, :, user_index, :]\n",
    "    book_factors_samples = trace.posterior[\"book_factors\"].values[:, :, book_indices, :]\n",
    "\n",
    "    num_samples = mu_samples.shape[1]  # Number of posterior samples\n",
    "    \n",
    "    # Compute expected rewards using posterior sampling\n",
    "    expected_rewards = np.mean(\n",
    "        np.exp(mu_samples[:, :, None] + user_bias_samples[:, :, None] + book_bias_samples +\n",
    "               np.sum(user_factors_samples[:, :, None, :] * book_factors_samples, axis=-1)), axis=1\n",
    "    )\n",
    "\n",
    "    # Compute variance (uncertainty measure)\n",
    "    rating_uncertainty = np.var(\n",
    "        np.exp(mu_samples[:, :, None] + user_bias_samples[:, :, None] + book_bias_samples +\n",
    "               np.sum(user_factors_samples[:, :, None, :] * book_factors_samples, axis=-1)), axis=1\n",
    "    )\n",
    "    \n",
    "    # Compute Bayesian regret\n",
    "    best_expected_reward = np.max(expected_rewards, axis=1)\n",
    "    regrets = best_expected_reward[:, None] - expected_rewards\n",
    "\n",
    "    # Cap regret to prevent extreme exploration\n",
    "    regrets = np.clip(regrets, 0, max_regret)\n",
    "\n",
    "    # Apply regret threshold\n",
    "    should_explore = regrets > regret_threshold\n",
    "\n",
    "    # Compute future learning potential\n",
    "    expected_future_gain = exploration_factor * rating_uncertainty\n",
    "\n",
    "    # Compute exploration-adjusted score\n",
    "    exploration_score = expected_rewards + expected_future_gain\n",
    "\n",
    "    # Rank books\n",
    "    ranked_books = np.argsort(-exploration_score, axis=1)  # Sort in descending order\n",
    "\n",
    "    # Select top-k books for recommendation\n",
    "    selected_books = [book_indices[i] for i in ranked_books[0, :top_k]]\n",
    "\n",
    "    return selected_books\n",
    "\n",
    "# Example usage: Recommend 5 books for a user\n",
    "user_id_example = 42  # Replace with an actual user ID\n",
    "book_pool = np.arange(num_books)  # Assuming all books are available\n",
    "\n",
    "recommended_books = bayes_general_recommendation(user_id_example, book_pool, trace, top_k=5)\n",
    "print(\"\\nTop-5 Recommended Books for User\", user_id_example, \":\", recommended_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision@5: 0.0010\n",
      "Average Recall@5: 0.0050\n",
      "Mean Absolute Error (MAE): 2.9559\n",
      "Root Mean Squared Error (RMSE): 3.0136\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of Precision, Recall, MAE, and RMSE in the top 5 recommendations\n",
    "\n",
    "def evaluate_recommendations(user_ids, book_pool, trace, top_k=5):\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_mae = 0\n",
    "    total_rmse = 0\n",
    "    user_count = len(user_ids)\n",
    "    \n",
    "    for user in user_ids:\n",
    "        actual_books = set(test_df[test_df['User-Index'] == user]['Book-Index'].values)\n",
    "        actual_ratings = test_df[test_df['User-Index'] == user]['Book-Rating'].values\n",
    "        recommended_books = set(bayes_general_recommendation(user, book_pool, trace, top_k))\n",
    "        \n",
    "        if len(actual_books) > 0:\n",
    "            precision = len(recommended_books & actual_books) / top_k\n",
    "            recall = len(recommended_books & actual_books) / len(actual_books)\n",
    "            predicted_ratings = np.array([trace.posterior[\"mu\"].mean().item() + trace.posterior[\"user_bias\"].mean(dim=(\"chain\", \"draw\")).values[user] + trace.posterior[\"book_bias\"].mean(dim=(\"chain\", \"draw\")).values[book] for book in actual_books])\n",
    "            \n",
    "            mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "            rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "        else:\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            mae = 0\n",
    "            rmse = 0\n",
    "        \n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_mae += mae\n",
    "        total_rmse += rmse\n",
    "    \n",
    "    avg_precision = total_precision / user_count\n",
    "    avg_recall = total_recall / user_count\n",
    "    avg_mae = total_mae / user_count\n",
    "    avg_rmse = total_rmse / user_count\n",
    "    \n",
    "    print(f\"Average Precision@{top_k}: {avg_precision:.4f}\")\n",
    "    print(f\"Average Recall@{top_k}: {avg_recall:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {avg_mae:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {avg_rmse:.4f}\")\n",
    "\n",
    "# Running evaluation\n",
    "book_pool = np.arange(num_books)\n",
    "evaluate_recommendations(test_user_ids, book_pool, trace, top_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new metrics for ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find books that user would actually like (lets say 7 rating or above)\n",
    "actual_books = {}\n",
    "threshold = 7  # Define threshold for relevant books\n",
    "\n",
    "for user in test_df['User-Index'].unique():\n",
    "    actual_books[user] = set(test_df[(test_df['User-Index'] == user) & (test_df['Book-Rating'] >= threshold)]['Book-Index'].values)\n",
    "\n",
    "#get recommended books for each user\n",
    "recommended_books = {}\n",
    "\n",
    "for user in test_df['User-Index'].unique():\n",
    "    recommended_books[user] = bayes_general_recommendation(user, df['Book-Index'].unique(), trace, top_k=5)\n",
    "\n",
    "\n",
    "#create book popularity variable\n",
    "book_popularity = df['Book-Index'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Reciprocal Rank (MRR)\n",
    "def mean_reciprocal_rank(recommended_books, actual_books):\n",
    "    \"\"\"\n",
    "    Computes the Mean Reciprocal Rank (MRR).\n",
    "    recommended_books: list of recommended book indices for each user.\n",
    "    actual_books: list of sets containing relevant book indices for each user.\n",
    "    \"\"\"\n",
    "    reciprocal_ranks = []\n",
    "    for rec, actual in zip(recommended_books, actual_books):\n",
    "        rank = next((i+1 for i, book in enumerate(rec) if book in actual), None)\n",
    "        if rank:\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "        else:\n",
    "            reciprocal_ranks.append(0)\n",
    "    return np.mean(reciprocal_ranks)\n",
    "\n",
    "# Normalized Discounted Cumulative Gain (NDCG)\n",
    "def ndcg_at_k(recommended_books, actual_books, k=5):\n",
    "    \"\"\"\n",
    "    Computes the Normalized Discounted Cumulative Gain (NDCG) at K.\n",
    "    recommended_books: list of recommended book indices for each user.\n",
    "    actual_books: list of sets containing relevant book indices for each user.\n",
    "    \"\"\"\n",
    "    def dcg(recs, actual):\n",
    "        return sum((1 / np.log2(i+2)) if rec in actual else 0 for i, rec in enumerate(recs[:k]))\n",
    "\n",
    "    ndcg_scores = []\n",
    "    for rec, actual in zip(recommended_books, actual_books):\n",
    "        actual_relevances = [1 if book in actual else 0 for book in rec[:k]]\n",
    "        ideal_dcg = dcg(sorted(actual_relevances, reverse=True), actual)\n",
    "        actual_dcg = dcg(rec, actual)\n",
    "        ndcg_scores.append(actual_dcg / ideal_dcg if ideal_dcg > 0 else 0)\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "# Coverage\n",
    "def coverage(recommended_books, total_books):\n",
    "    \"\"\"\n",
    "    Measures recommendation diversity as the percentage of books recommended.\n",
    "    recommended_books: list of recommended book indices for each user.\n",
    "    total_books: total number of books in the dataset.\n",
    "    \"\"\"\n",
    "    unique_books = set(book for rec in recommended_books for book in rec)\n",
    "    return len(unique_books) / total_books\n",
    "\n",
    "# Novelty (measuring unexpectedness)\n",
    "def novelty(recommended_books, book_popularity, k=5):\n",
    "    \"\"\"\n",
    "    Computes novelty based on how rare the recommended books are.\n",
    "    book_popularity: Dictionary mapping book index to its popularity score.\n",
    "    \"\"\"\n",
    "    novelty_scores = []\n",
    "    for rec in recommended_books:\n",
    "        avg_popularity = np.mean([book_popularity.get(book, 0) for book in rec[:k]])\n",
    "        novelty_scores.append(1 / (1 + avg_popularity))  # Lower popularity → higher novelty\n",
    "    return np.mean(novelty_scores)\n",
    "\n",
    "# Example Usage\n",
    "# recommended_books = [[101, 203, 405], [312, 120, 305]]  # Example user recommendations\n",
    "# actual_books = [{101, 405}, {120}]  # Example actual relevant books\n",
    "# total_books = 1000  # Assume dataset has 1000 books\n",
    "# book_popularity = {101: 500, 203: 100, 405: 50, 312: 300, 120: 20, 305: 80}  # Example popularity\n",
    "\n",
    "# print(\"MRR:\", mean_reciprocal_rank(recommended_books, actual_books))\n",
    "# print(\"NDCG@5:\", ndcg_at_k(recommended_books, actual_books, k=5))\n",
    "# print(\"Coverage:\", coverage(recommended_books, total_books))\n",
    "# print(\"Novelty:\", novelty(recommended_books, book_popularity, k=5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasterBayesianVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
